{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c5d0f3-0fb3-47a9-bbcd-b90959f7e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import TimeDistributed, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b354200f-d992-4282-ab29-5a905f0037de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10\n",
    "def frame_extract(path):\n",
    "    vidObj = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    success = True\n",
    "    while success:\n",
    "        success, image = vidObj.read()\n",
    "        if success:\n",
    "            frames.append(image)\n",
    "    return frames\n",
    "\n",
    "# Load and preprocess video frames\n",
    "def load_video_frames(video_path, sequence_length):\n",
    "    frames = frame_extract(video_path)\n",
    "    num_frames = len(frames)\n",
    "    if num_frames < sequence_length:\n",
    "        # Pad frames if the video is shorter than the desired sequence length\n",
    "        frames += [frames[-1]] * (sequence_length - num_frames)\n",
    "    elif num_frames > sequence_length:\n",
    "        # Randomly select a sequence of frames from the video\n",
    "        start_index = random.randint(0, num_frames - sequence_length)\n",
    "        frames = frames[start_index: start_index + sequence_length]\n",
    "\n",
    "    # Resize frames to (112, 112)\n",
    "    resized_frames = []\n",
    "    for frame in frames:\n",
    "        resized_frame = cv2.resize(frame, (224, 224)).astype(np.float32)\n",
    "        resized_frames.append(resized_frame)\n",
    "\n",
    "    # Convert frames to numpy array and preprocess\n",
    "    frames_array = np.array(resized_frames, dtype=np.float32)\n",
    "    frames_array = preprocess_input(frames_array)\n",
    "\n",
    "    # Get label\n",
    "    video_name = video_path.split('/')[-1]\n",
    "    label = labels.loc[labels[\"file\"] == video_name, \"label\"].values\n",
    "    if len(label) == 0:\n",
    "        return None, None\n",
    "    label = label[0]\n",
    "    if label == 'FAKE':\n",
    "        label = 0\n",
    "    elif label == 'REAL':\n",
    "        label = 1\n",
    "\n",
    "    return frames_array, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d2371fc-c30b-457e-8f98-422f817218d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mq/wyrpjx1s0rl_61k7fbhqxxgw0000gn/T/ipykernel_16711/2387045404.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Fake'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 가져온 영상을 모델에 입력하기 위해 전처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprocessed_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_video_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 예시로 전처리 함수를 사용하도록 가정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 모델에 입력하기 위해 차원을 추가 (예시로 1개의 영상이므로 배치 차원을 추가)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/mq/wyrpjx1s0rl_61k7fbhqxxgw0000gn/T/ipykernel_16711/1497110248.py\u001b[0m in \u001b[0;36mload_video_frames\u001b[0;34m(video_path, sequence_length)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Get label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mvideo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# 저장된 모델 로드\n",
    "model = load_model('best_model_1.h5')\n",
    "\n",
    "# 테스트 데이터셋에서 영상 하나를 가져옴 (예시로 첫 번째 영상)\n",
    "test_video = \"./data/test/fake/aabdnomlru.mp4\"\n",
    "test_label = 'Fake'\n",
    "# 가져온 영상을 모델에 입력하기 위해 전처리\n",
    "processed_video = load_video_frames(test_video, 10)  # 예시로 전처리 함수를 사용하도록 가정\n",
    "\n",
    "# 모델에 입력하기 위해 차원을 추가 (예시로 1개의 영상이므로 배치 차원을 추가)\n",
    "processed_video = np.expand_dims(processed_video, axis=0)\n",
    "\n",
    "# 모델로 예측 수행\n",
    "predictions = model.predict(processed_video)\n",
    "\n",
    "# 예측 결과 확인\n",
    "predicted_label = np.argmax(predictions)\n",
    "if predicted_label == 0:\n",
    "    predicted_class = 'Fake'\n",
    "else:\n",
    "    predicted_class = 'Real'\n",
    "\n",
    "# 실제 레이블 확인\n",
    "if test_label == 0:\n",
    "    actual_class = 'Fake'\n",
    "else:\n",
    "    actual_class = 'Real'\n",
    "\n",
    "# 결과 출력\n",
    "print('Predicted class:', predicted_class)\n",
    "print('Actual class:', actual_class)\n",
    "\n",
    "# 영상 시각화 (옵션)\n",
    "cv2.imshow('Test Video', test_video)  # OpenCV를 사용하여 영상을 시각화할 수 있음\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d24c153-bb70-4b01-96ce-2ebf84e4a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 10, 112, 11  0           []                               \n",
      "                                2, 3)]                                                            \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)             (None, 10, 112, 112  2624        ['input[0][0]']                  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)             (None, 10, 112, 112  128         ['input[0][0]']                  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " tf_op_layer_add_6 (TensorFlowO  (None, 10, 112, 112  0          ['conv3d_12[0][0]',              \n",
      " pLayer)                        , 32)                             'conv3d_13[0][0]']              \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 10, 112, 112  0           ['tf_op_layer_add_6[0][0]']      \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d_6 (MaxPooling3D)  (None, 10, 56, 56,   0          ['activation_6[0][0]']           \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)             (None, 10, 56, 56,   55360       ['max_pooling3d_6[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_15 (Conv3D)             (None, 10, 56, 56,   2112        ['max_pooling3d_6[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " tf_op_layer_add_7 (TensorFlowO  (None, 10, 56, 56,   0          ['conv3d_14[0][0]',              \n",
      " pLayer)                        64)                               'conv3d_15[0][0]']              \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 10, 56, 56,   0           ['tf_op_layer_add_7[0][0]']      \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_7 (MaxPooling3D)  (None, 10, 28, 28,   0          ['activation_7[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_16 (Conv3D)             (None, 10, 28, 28,   221312      ['max_pooling3d_7[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_17 (Conv3D)             (None, 10, 28, 28,   8320        ['max_pooling3d_7[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " tf_op_layer_add_8 (TensorFlowO  (None, 10, 28, 28,   0          ['conv3d_16[0][0]',              \n",
      " pLayer)                        128)                              'conv3d_17[0][0]']              \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 10, 28, 28,   0           ['tf_op_layer_add_8[0][0]']      \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " max_pooling3d_8 (MaxPooling3D)  (None, 10, 14, 14,   0          ['activation_8[0][0]']           \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 10, 128)     0           ['max_pooling3d_8[0][0]']        \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 128)          131584      ['time_distributed_2[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          16512       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            129         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 438,081\n",
      "Trainable params: 438,081\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# 저장된 모델 로드\n",
    "model = load_model('best_model_1.h5')\n",
    "\n",
    "# 모델의 요약 정보 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c4e9a-d457-4573-9047-b95b642fa328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_v2.7",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
